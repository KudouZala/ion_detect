import os
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from pathlib import Path

import numpy as np
import pandas as pd
from itertools import combinations




def fit_res_analysis(root_path, ion_density):
    # Output directory two levels above current script
    current_dir = Path(__file__).resolve()
    output_dir = current_dir.parents[1] / "eis_fit_analysis_results"
    output_dir.mkdir(parents=True, exist_ok=True)

    # Ion type mapping: Chinese name â†’ Symbol
    ion_types = {
        "é’ ç¦»å­": "Naâº",
        "é’™ç¦»å­": "CaÂ²âº",
        "é“¬ç¦»å­": "CrÂ³âº",
        "é•ç¦»å­": "NiÂ²âº",
        "é“œç¦»å­": "CuÂ²âº",
        "é“ç¦»å­": "FeÂ³âº",
        "é“ç¦»å­": "AlÂ³âº"
    }

    # Containers for two diffs: (row2-row1) and (row3-row1)
    ion_data_21 = {symbol: [] for symbol in ion_types.values()}
    ion_data_31 = {symbol: [] for symbol in ion_types.values()}

    # ---------- helpers ----------
    def find_matching_rows(df):
        """Return indices (row1_idx, row2_idx, row3_idx) based on patterns in first column."""
        col0 = df.iloc[:, 0].astype(str)

        # row1
        row1_mask = col0.str.contains(
            r"(_ion_columnå¾ªç¯1[/ï¼]1_å·¥æ­¥ç»„1\(å·¥æ­¥ç»„\)\(3[/ï¼]\d+\)_å·¥æ­¥3\(é˜»æŠ—\)_greater_than_0)"
            r"|(_ion_columnå¾ªç¯1[/ï¼]1_å·¥æ­¥ç»„2\(å·¥æ­¥ç»„\)\(3[/ï¼]\d+\)_å·¥æ­¥3\(é˜»æŠ—\)_greater_than_0)"
            r"|(_ion_columnå¾ªç¯1[/ï¼]1_å·¥æ­¥ç»„3\(å·¥æ­¥ç»„\)\(3[/ï¼]\d+\)_å·¥æ­¥3\(é˜»æŠ—\)_greater_than_0)"
            r"|(_ion_column_å¾ªç¯1[/ï¼]1_å·¥æ­¥ç»„1\(å·¥æ­¥ç»„\)\(3[/ï¼]\d+\)_å·¥æ­¥3\(é˜»æŠ—\)_greater_than_0)"
            r"|(_ion_column_å¾ªç¯1[/ï¼]1_å·¥æ­¥ç»„2\(å·¥æ­¥ç»„\)\(3[/ï¼]\d+\)_å·¥æ­¥3\(é˜»æŠ—\)_greater_than_0)"
            r"|(_ion_column_å¾ªç¯1[/ï¼]1_å·¥æ­¥ç»„3\(å·¥æ­¥ç»„\)\(3[/ï¼]\d+\)_å·¥æ­¥3\(é˜»æŠ—\)_greater_than_0)"
            r"|(_ion_column_3)",
            na=False
        )


        # row2
        row2_mask = col0.str.contains(
            r"(_ion_3_)"
            r"|(_ionå¾ªç¯1[/ï¼]1_å·¥æ­¥ç»„2\(å·¥æ­¥ç»„\)\(3[/ï¼]\d+\)_å·¥æ­¥3\(é˜»æŠ—\)_greater_than_0)"
            r"|(_ionå¾ªç¯1[/ï¼]1_å·¥æ­¥ç»„1\(å·¥æ­¥ç»„\)\(3[/ï¼]\d+\)_å·¥æ­¥3\(é˜»æŠ—\)_greater_than_0)",
            r"|(_ionå¾ªç¯1[/ï¼]1_å·¥æ­¥ç»„3\(å·¥æ­¥ç»„\)\(3[/ï¼]\d+\)_å·¥æ­¥3\(é˜»æŠ—\)_greater_than_0)",
            na=False
        )

        # row3ï¼ˆä½ çš„â€œæ¢å¤/renewâ€ä¸¤ç§å†™æ³•åšâ€œæˆ–â€ï¼‰
        # row3_mask = col0.str_contains if hasattr(col0, 'str_contains') else col0.str.contains
        row3_mask = col0.str.contains(
            r"(_ion_column_renew_H2SO4_3)"
            r"|(_ion_column_renew_3)"
            r"|(_ion_column_renewå¾ªç¯1[/ï¼]1_å·¥æ­¥ç»„2\(å·¥æ­¥ç»„\)\(3[/ï¼]\d+\)_å·¥æ­¥3\(é˜»æŠ—\)_greater_than_0)"
            r"|(_ion_column_renewå¾ªç¯1[/ï¼]1_å·¥æ­¥ç»„1\(å·¥æ­¥ç»„\)\(3[/ï¼]\d+\)_å·¥æ­¥3\(é˜»æŠ—\)_greater_than_0)"
            r"|(_ion_column_renewå¾ªç¯1[/ï¼]1_å·¥æ­¥ç»„3\(å·¥æ­¥ç»„\)\(3[/ï¼]\d+\)_å·¥æ­¥3\(é˜»æŠ—\)_greater_than_0)",
            na=False
        )

        row1_idx = row1_mask.idxmax() if row1_mask.any() else None
        row2_idx = row2_mask.idxmax() if row2_mask.any() else None
        row3_idx = row3_mask.idxmax() if row3_mask.any() else None
        return row1_idx, row2_idx, row3_idx





    def _pair_mean_from_expanding_window(df, start_idx, col, window_init=5, rel_thresh=0.05):
        """
        æ‰©å¤§çª—å£ç‰ˆï¼š
        - èµ·ç‚¹ fixed = start_idxï¼Œåˆå§‹çª—å£å¤§å° window_initï¼ˆè‹¥ä¸è¶³åˆ™ç”¨èƒ½å–åˆ°çš„è¡Œæ•°ï¼‰ï¼Œ
            ç„¶åæ¯æ¬¡æŠŠçª—å£æœ«ç«¯æ‰©å¤§ 1 è¡Œï¼Œç›´åˆ°æ»¡è¶³æ¡ä»¶æˆ–åˆ°è¡¨å°¾ã€‚
        - æ¯ä¸ªçª—å£å†…å…ˆä¸¢å¼ƒ >5 ä¸ NaNï¼›è‹¥æœ‰æ•ˆå€¼ <2 åˆ™ç»§ç»­æ‰©å¤§ã€‚
        - åœ¨çª—å£æœ‰æ•ˆå€¼ä¸­æ‰¾åˆ°â€œæœ€è¿‘çš„ä¸€å¯¹â€ï¼ˆç»å¯¹å·®æœ€å°ï¼‰ï¼›è‹¥è¯¥å¯¹ç›¸å¯¹å·® <= rel_thresh(é»˜è®¤5%)ï¼Œ
            ç«‹å³è¿”å›è¿™å¯¹çš„å‡å€¼ã€‚
        - è‹¥åˆ°è¡¨å°¾ä»æœªå‘½ä¸­ 5%ï¼Œåˆ™åœ¨â€œèµ·ç‚¹åˆ°è¡¨å°¾â€çš„æ•´ä¸ªèŒƒå›´å†…ï¼Œå–å…¨å±€æœ€è¿‘çš„ä¸€å¯¹ï¼ˆä»åªç”¨ â‰¤5ï¼‰ä½œé€€åŒ–è¿”å›å…¶å‡å€¼ã€‚
        - è‹¥å…¨èŒƒå›´å†…æœ‰æ•ˆå€¼(â‰¤5 ä¸”é NaN)ä¸è¶³ä¸¤æ¡ï¼Œåˆ™æŠ›å‡ºè¯¦ç»† ValueErrorã€‚
        """
        n_rows = len(df)
        eps = 1e-9

        if start_idx is None:
            raise ValueError(f"[å–å€¼å¤±è´¥] èµ·ç‚¹è¡Œ start_idx ä¸º Noneï¼ˆåˆ—ï¼š{col}ï¼‰ã€‚")
        if not (0 <= start_idx < n_rows):
            raise ValueError(f"[å–å€¼å¤±è´¥] èµ·ç‚¹è¡Œ start_idx={start_idx} è¶…å‡ºè¡Œæ•°èŒƒå›´ [0, {n_rows-1}]ï¼ˆåˆ—ï¼š{col}ï¼‰ã€‚")

        # èµ·ç‚¹è¡Œè¾…åŠ©ä¿¡æ¯ï¼ˆç”¨äºä»»ä½•å¤±è´¥æ—¶è¾“å‡ºï¼‰
        try:
            start_val = df.iloc[start_idx][col]
            start_val_str = "NA" if pd.isna(start_val) else f"{float(start_val):.6g}"
            try:
                first_col_text = str(df.iloc[start_idx, 0])
            except Exception:
                first_col_text = None
        except Exception as e:
            raise ValueError(
                f"[å–å€¼å¤±è´¥] æ— æ³•è¯»å–èµ·ç‚¹è¡Œæ•°æ®ï¼ˆåˆ—ï¼š{col}ï¼Œstart_idx={start_idx}ï¼‰ã€‚åŸå› ï¼š{e}"
            )

        # åˆå§‹çª—å£ç»ˆç‚¹ï¼ˆå…è®¸è¡¨å°¾å¤„åˆå§‹å°± < window_initï¼‰
        end_idx = min(n_rows - 1, start_idx + max(1, window_init) - 1)

        # å…¨å±€é€€åŒ–å€™é€‰ï¼ˆåœ¨æ•´ä¸ªæ‰©å¼ è¿‡ç¨‹ä¸­ç»´æŠ¤ï¼‰
        global_best = None  # (abs_diff, mean_ab, (row_i,row_j), (val_i,val_j))

        # ä»åˆå§‹çª—å£å¼€å§‹ä¸€è·¯æ‰©å¤§åˆ°è¡¨å°¾
        while end_idx < n_rows:
            # æ”¶é›†å½“å‰çª—å£å†…å€¼ï¼Œä¸¢å¼ƒ >5 å’Œ NaN
            valid_vals, valid_rows = [], []
            raw = []  # (row, val_str, tag) tagâˆˆ{"OK",">5","NA"} ä»…ç”¨äºæŠ¥é”™å±•ç¤º
            for r in range(start_idx, end_idx + 1):
                v = df.iloc[r][col]
                if pd.isna(v):
                    raw.append((r, "NA", "NA"))
                else:
                    fv = float(v)
                    if fv > 5:
                        raw.append((r, f"{fv:.6g}", ">5"))
                    else:
                        raw.append((r, f"{fv:.6g}", "OK"))
                        valid_vals.append(fv)
                        valid_rows.append(r)

            # å½“å‰çª—å£å†…ä¸è¶³ä¸¤æ¡æœ‰æ•ˆå€¼ â†’ æ‰©å¤§çª—å£
            if len(valid_vals) >= 2:
                # çª—å£å†…â€œæœ€è¿‘çš„ä¸€å¯¹â€
                best_absdiff = None
                best_pair_vals = None
                best_pair_rows = None
                for i in range(len(valid_vals)):
                    a = valid_vals[i]
                    for j in range(i + 1, len(valid_vals)):
                        b = valid_vals[j]
                        ad = abs(a - b)
                        if (best_absdiff is None) or (ad < best_absdiff):
                            best_absdiff = ad
                            best_pair_vals = (a, b)
                            best_pair_rows = (valid_rows[i], valid_rows[j])

                # æ›´æ–°å…¨å±€é€€åŒ–å€™é€‰
                mean_ab = 0.5 * (best_pair_vals[0] + best_pair_vals[1])
                rel = best_absdiff / max(abs(mean_ab), eps)
                if (global_best is None) or (best_absdiff < global_best[0]):
                    global_best = (best_absdiff, mean_ab, best_pair_rows, best_pair_vals)

                # å‘½ä¸­ 5% ç«‹å³è¿”å›
                if rel <= rel_thresh:
                    return mean_ab

            # æ‰©å¤§ 1 è¡Œï¼›è‹¥å·²åˆ°è¡¨å°¾åˆ™è·³å‡ºå¾ªç¯
            if end_idx == n_rows - 1:
                break
            end_idx += 1

        # æ‰©åˆ°è¡¨å°¾ä»æœªå‘½ä¸­ 5%ï¼šå…¨å±€é€€åŒ–
        if global_best is not None:
            return global_best[1]

        # å…¨èŒƒå›´å†…æ²¡æœ‰ä¸¤æ¡æœ‰æ•ˆå€¼ï¼ˆâ‰¤5 ä¸”é NaNï¼‰
        # ä¸ºäº†ä¾¿äºå®šä½ï¼Œè¾“å‡ºèµ·ç‚¹â†’è¡¨å°¾çš„ç®€è¦æ‘˜è¦ï¼ˆæœ€å¤šåˆ—å‡ºå‰/åçš„è‹¥å¹²è¡Œï¼‰
        summary = []
        MAX_LIST = 12  # æ§åˆ¶æŠ¥é”™ä¿¡æ¯é•¿åº¦
        all_rows = list(range(start_idx, n_rows))
        head = all_rows[:MAX_LIST//2]
        tail = all_rows[-MAX_LIST//2:] if len(all_rows) > MAX_LIST//2 else []
        show_rows = head + (["..."] if len(all_rows) > MAX_LIST else []) + tail

        for r in show_rows:
            if r == "...":
                summary.append("...")
                continue
            v = df.iloc[r][col]
            if pd.isna(v):
                summary.append((r, "NA", "NA"))
            else:
                fv = float(v)
                if fv > 5:
                    summary.append((r, f"{fv:.6g}", ">5"))
                else:
                    summary.append((r, f"{fv:.6g}", "OK"))

        raise ValueError(
            "[å–å€¼å¤±è´¥] ä»èµ·ç‚¹è¡Œ {s} æ‰©å¤§åˆ°è¡¨å°¾çš„ä»»ä½•çª—å£å†…ï¼Œéƒ½æ²¡æœ‰ä¸¤æ¡æœ‰æ•ˆå€¼(â‰¤5 ä¸”é NaN)ï¼ˆåˆ—ï¼š{col}ï¼‰ã€‚\n"
            "  - èµ·ç‚¹è¡Œé¦–åˆ—æ–‡æœ¬: {head}\n"
            "  - èµ·ç‚¹è¡Œè¯¥åˆ—å€¼: {sv}\n"
            "  - èµ·ç‚¹â†’è¡¨å°¾(éƒ¨åˆ†)å€¼æ‘˜è¦(è¡Œå·,å€¼,æ ‡è®°): {sum}".format(
                s=start_idx, col=col, head=first_col_text, sv=start_val_str, sum=summary
            )
        )


    def compute_diff(df, row1_idx, rowx_idx, columns, window_init=5, rel_thresh=0.05):
        """
        å¯¹æ¯ä¸ªåˆ— colï¼š
        v1 = _pair_mean_from_expanding_window(df, row1_idx, col, ...)
        v2 = _pair_mean_from_expanding_window(df, rowx_idx, col, ...)
        è¿”å›ï¼š
        np.array(v2_vals - v1_vals, dtype=float)
        ä»»ä¸€æ­¥å¤±è´¥ä¼šæŠ›å‡ºåŒ…å«â€œv1/v2 é˜¶æ®µ + åˆ—å + èµ·ç‚¹ä¿¡æ¯â€çš„è¯¦ç»† ValueErrorã€‚
        """
        v1_vals, v2_vals = [], []
        for col in columns:
            try:
                v1 = _pair_mean_from_expanding_window(
                    df, row1_idx, col, window_init=window_init, rel_thresh=rel_thresh
                )
            except Exception as e:
                raise ValueError(f"[v1å–å€¼å¤±è´¥] åˆ—ï¼š{col}ï¼Œstart_idx={row1_idx}ã€‚è¯¦æƒ…ï¼š{e}")

            try:
                v2 = _pair_mean_from_expanding_window(
                    df, rowx_idx, col, window_init=window_init, rel_thresh=rel_thresh
                )
            except Exception as e:
                raise ValueError(f"[v2å–å€¼å¤±è´¥] åˆ—ï¼š{col}ï¼Œstart_idx={rowx_idx}ã€‚è¯¦æƒ…ï¼š{e}")

            v1_vals.append(v1)
            v2_vals.append(v2)

        v1_vals = np.array(v1_vals, dtype=float)
        v2_vals = np.array(v2_vals, dtype=float)
        return v2_vals - v1_vals




    def group_and_mean(diffs_list):
        """
        diffs_list: list of np.array with variable lengths.
        Return mean_vec, used_len, used_count.
        Strategy: group by length; pick the length group with most samples.
        """
        if not diffs_list:
            return None, 0, 0
        grouped = {}
        for d in diffs_list:
            if isinstance(d, (list, np.ndarray)):
                grouped.setdefault(len(d), []).append(np.array(d))
        # choose the length with the most samples
        best_len = max(grouped.keys(), key=lambda k: len(grouped[k]))
        valid = np.vstack(grouped[best_len])
        return np.mean(valid, axis=0), best_len, valid.shape[0]

    # ---------- walk & collect ----------
    for folder_name in os.listdir(root_path):
        if ion_density not in folder_name:
            continue

        for cn_name, symbol in ion_types.items():
            if cn_name not in folder_name:
                continue

            folder_path = os.path.join(root_path, folder_name)
            if not os.path.isdir(folder_path):
                continue

            for subfolder in os.listdir(folder_path):
                subfolder_path = os.path.join(folder_path, subfolder)
                if not os.path.isdir(subfolder_path):
                    continue

                # ä»…å¤„ç†çˆ¶æ–‡ä»¶å¤¹ï¼ˆå³ file çš„ç›´æ¥çˆ¶çº§ subfolderï¼‰åä¸­åŒ…å«â€œæ¢å¤â€
                # ä»…å¤„ç†ç»å¯¹è·¯å¾„ä¸­åŒ…å«â€œæ¢å¤â€çš„æ–‡ä»¶å¤¹
                # if "æ¢å¤" not in subfolder_path:
                #     print(f"æœªæ‰¾åˆ°æ¢å¤å­—æ ·ï¼š{subfolder_path}")
                #     continue

                for file in os.listdir(subfolder_path):
                    if not file.endswith("_sorted.xlsx"):
                        continue

                    file_path = os.path.join(subfolder_path, file)
                    try:
                        print(f"\nğŸ“„ Processing file: {file_path}")
                        df = pd.read_excel(file_path)

                        row1_idx, row2_idx, row3_idx = find_matching_rows(df)
                        if row1_idx is None:
                            print("  âš ï¸ row1 æœªæ‰¾åˆ°ï¼Œè·³è¿‡")
                            continue
                       
                        

                        # å“ªäº›åˆ—å¯ç”¨
                        full_cols = ["R0", "P1w", "P1n", "R1", "P2w", "P2n", "R2", "P3w", "P3n", "R3"]
                        short_cols = ["R0", "P1w", "P1n", "R1", "P2w", "P2n", "R2"]

                        if all(c in df.columns for c in full_cols):
                            r_cols = ["R0", "R1", "R2", "R3"]
                        elif all(c in df.columns for c in short_cols):
                            r_cols = ["R0", "R1", "R2"]
                        else:
                            print("  âš ï¸ ç¼ºå°‘ R åˆ—ï¼Œè·³è¿‡")
                            continue

                        if row2_idx is None:
                            print("  âš ï¸ row2 æœªæ‰¾åˆ°ï¼Œè·³è¿‡")
                            continue
                        # row2 - row1
                        if row2_idx is not None:
                            diff_21 = compute_diff(df, row1_idx, row2_idx, r_cols)
                            if diff_21 is not None:
                                ion_data_21[symbol].append(diff_21)
                        
                        if row3_idx is None:
                            print("  âš ï¸ row3 æœªæ‰¾åˆ°ï¼Œè·³è¿‡")
                            continue
                        # row3 - row1
                        if row3_idx is not None:
                            diff_31 = compute_diff(df, row1_idx, row3_idx, r_cols)
                            if diff_31 is not None:
                                ion_data_31[symbol].append(diff_31)

                    except Exception as e:
                        print(f"âŒ Failed to read: {file_path}, Error: {e}")

    # ---------- aggregate ----------
    mean_diffs_21, mean_diffs_31 = {}, {}
    counts_21, counts_31 = {}, {}
    max_r_count = 0

    print("\n====== æ±‡æ€»ç»Ÿè®¡ ======")
    for ion in ion_types.values():
        # 2-1
        mean21, len21, n21 = group_and_mean(ion_data_21[ion])
        # 3-1
        mean31, len31, n31 = group_and_mean(ion_data_31[ion])

        if mean21 is not None:
            mean_diffs_21[ion] = mean21
            counts_21[ion] = n21
            max_r_count = max(max_r_count, len(mean21))
            print(f"ğŸ“Š {ion} 2-1 å¹³å‡(æ ·æœ¬ {n21}, é•¿åº¦ {len21}): " + ", ".join([f"R{i}:{v:.6f}" for i, v in enumerate(mean21)]))
        if mean31 is not None:
            mean_diffs_31[ion] = mean31
            counts_31[ion] = n31
            max_r_count = max(max_r_count, len(mean31))
            print(f"ğŸ“Š {ion} 3-1 å¹³å‡(æ ·æœ¬ {n31}, é•¿åº¦ {len31}): " + ", ".join([f"R{i}:{v:.6f}" for i, v in enumerate(mean31)]))

    # è‹¥ä¸€ä¸ªç¦»å­åªåœ¨å…¶ä¸­ä¸€ç»„æœ‰æ•°æ®ï¼Œä¹Ÿå…è®¸ç”»/å†™
    # ---------- plot ----------
    plt.figure(figsize=(10, 6))

    # ç”¨ tab10 åšåŸºè‰²ï¼ŒåŒä¸€ç¦»å­æ·±æµ…ä¸¤ç§
    base_colors = plt.get_cmap("tab10")
    ion_list = [ion for ion in ion_types.values() if (ion in mean_diffs_21 or ion in mean_diffs_31)]

    for idx, ion in enumerate(ion_list):
        color = base_colors(idx % 10)

        # 2-1 (æ·±è‰²)
        if ion in mean_diffs_21:
            vals = mean_diffs_21[ion]
            labels = ["R0", "R1", "R2", "R3"][:len(vals)]
            plt.plot(labels, vals, marker='x', label=f"{ion} contamined", color=color, linewidth=2, alpha=0.5, linestyle="--")

        # 3-1 (æµ…è‰²)
        if ion in mean_diffs_31:
            vals = mean_diffs_31[ion]
            labels = ["R0", "R1", "R2", "R3"][:len(vals)]
            # æµ…è‰²ï¼šåŒè‰² + æ›´é«˜é€æ˜åº¦
            plt.plot(labels, vals, marker='o', label=f"{ion} recovered", color=color, linewidth=2, alpha=1)

    plt.xlabel("Resistance Component")
    plt.ylabel("Change (Î”Ohm)")
    plt.title(f"Impedance Change (contaminated vs recovered) ")
    plt.grid(True, alpha=0.3)
    plt.legend(ncol=2)
    plt.tight_layout()

    date_suffix = Path(root_path).name
    plot_path = output_dir / f"resistance_change_plot_2v3_{date_suffix}_{ion_density}.png"
    plt.savefig(plot_path, dpi=200)
    plt.show()

    # ---------- save CSV ----------
    # ç»Ÿä¸€åˆ—å¤´
    excel_columns = ["R0", "R1", "R2", "R3"][:max_r_count]

    # ç»„è£…ä¸¤ä¸ª DataFrameï¼Œå¹¶åœ¨åˆ—ååŠ åç¼€
    def to_df(dct, suffix):
        if not dct:
            return pd.DataFrame()
        df = pd.DataFrame.from_dict(dct, orient="index")
        df.columns = [f"{c}_{suffix}" for c in excel_columns[:df.shape[1]]]
        return df

    df21 = to_df(mean_diffs_21, "2minus1")
    df31 = to_df(mean_diffs_31, "3minus1")

    # æ ·æœ¬æ•°ä¹Ÿä¿å­˜
    s21 = pd.Series(counts_21, name="n_samples_2minus1")
    s31 = pd.Series(counts_31, name="n_samples_3minus1")

    # åˆå¹¶
    df_out = pd.concat([df21, df31, s21, s31], axis=1)

    excel_filename = f"resistance_change_summary_2v3_{date_suffix}_{ion_density}.xlsx"
    excel_path = output_dir / excel_filename
    df_out.index.name = "Ion"
    df_out.to_excel(excel_path)

    print(f"\nâœ… Done! Plot saved to: {plot_path}")
    print(f"           Excel saved to: {excel_path}")

# === è°ƒç”¨ç¤ºä¾‹ï¼ˆä¸åŸè„šæœ¬ä¸€è‡´ï¼‰ ===
if __name__ == "__main__":
    from pathlib import Path
    date_folder = "20250724"   # ä½ çš„æ—¥æœŸå­—ç¬¦ä¸²
    current_dir = Path(__file__).resolve()
    root_path = current_dir.parents[1] / "eis_fit_results" / date_folder
    ion_density = '2ppm'
    fit_res_analysis(root_path=root_path, ion_density=ion_density)
