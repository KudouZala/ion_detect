import os
import re
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import argparse
from pathlib import Path
import matplotlib
import matplotlib.pyplot as plt
from matplotlib import rcParams
import subprocess

import matplotlib.pyplot as plt
from matplotlib import rcParams
import matplotlib
# è®¾ç½®å­—ä½“ä¸º Noto Sans CJKï¼Œè¿™ç§å­—ä½“æ”¯æŒä¸­æ–‡
# rcParams['font.family'] = ['Noto Sans CJK SC']  # ç®€ä½“ä¸­æ–‡
import os
from matplotlib import rcParams
import matplotlib.font_manager as fm

# è®¾ç½®æ”¯æŒä¸­æ–‡çš„å­—ä½“
# æ ¹æ®æ“ä½œç³»ç»Ÿé€‰æ‹©åˆé€‚çš„ä¸­æ–‡å­—ä½“
if os.name == 'posix':
    # Linux æˆ– macOSï¼Œå°è¯•ä½¿ç”¨å¸¸è§çš„å¼€æºä¸­æ–‡å­—ä½“
    # .ttc æ˜¯ä¸€ç§å­—ä½“é›†åˆæ ¼å¼ï¼ˆåŒ…å«å¤šä¸ªå­—ä½“ï¼‰
    # matplotlib é»˜è®¤æ— æ³•ç›´æ¥è§£æ .ttc ä¸­çš„å¤šä¸ªå­å­—ä½“åï¼Œå› æ­¤éœ€è¦é€šè¿‡ FontProperties ç²¾ç¡®æŒ‡å®šä¸€ä¸ªå­—ä½“ã€‚
    # æ‰‹åŠ¨åŠ è½½ttcå­—ä½“
    font_prop = fm.FontProperties(fname="/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc")
    font_name = font_prop.get_name()
    rcParams['font.sans-serif'] = font_name
elif os.name == 'nt':
    # Windows ç³»ç»Ÿï¼Œé»˜è®¤ä½¿ç”¨ SimHei
    rcParams['font.sans-serif'] = ['SimHei']

def plot_attributions_from_folder(folder_path, save_fig=False):
    print(f"ğŸ“‚ æ­£åœ¨æ£€æŸ¥æ–‡ä»¶å¤¹: {folder_path}")
    files = os.listdir(folder_path)
    print(f"ğŸ“ æ‰¾åˆ° {len(files)} ä¸ªæ–‡ä»¶")

    # è‡ªåŠ¨æ‰¾ pred ID å’Œ prefix
    pred_pattern = re.compile(r"(.*)_(saliency|ig)_pred(\d+)\.csv")
    pred_dict = {}
    for f in files:
        match = pred_pattern.match(f)
        if match:
            prefix, typ, pred_num = match.groups()
            key = (prefix, pred_num)
            pred_dict.setdefault(key, {})[typ] = f

    print(f"ğŸ” æ‰¾åˆ° {len(pred_dict)} ä¸ªé¢„æµ‹ç¼–å·ç»„")

    # ==== è‡ªåŠ¨æ£€æµ‹æ—¶é—´ç‚¹æ•° & é¢‘ç‡ç‚¹æ•° ====
    # å‡è®¾ Attention æ–‡ä»¶çš„ token æ•°æ»¡è¶³ï¼š
    # token_count = 1(CLASS) + T(æ—¶é—´token) + T*freq_points(é¢‘ç‡token)
    #            = T*(freq_points + 1) + 1
    attn_files = [f for f in files if "_attn_" in f and "param_attn_" not in f]
    if len(attn_files) > 0:
        sample_attn_file = os.path.join(folder_path, attn_files[0])
        sample_data = pd.read_csv(sample_attn_file, header=None)
        token_count = sample_data.shape[1] if sample_data.shape[0] == 1 else sample_data.shape[0]
        print(f"ğŸ” æ£€æµ‹åˆ°ç¤ºä¾‹ Attention æ–‡ä»¶: {attn_files[0]}, token æ•°={token_count}")

        freq_points = None
        num_time_points = None

        # æšä¸¾å€™é€‰ç»„åˆï¼šfreq_points âˆˆ {64,63}, æ—¶é—´ç‚¹ âˆˆ {4,3,2}
        for f in [64, 63]:
            for t in [4, 3, 2]:
                if token_count == t * (f + 1) + 1:
                    freq_points = f
                    num_time_points = t
                    break
            if freq_points is not None:
                break

        if freq_points is None:
            # å…œåº•ï¼šä¿æŒåŸæ¥çš„åˆ¤æ–­é€»è¾‘ï¼Œé»˜è®¤ä¸º 4 ä¸ªæ—¶é—´ç‚¹
            if token_count == 4 * 64 + 4 + 1:
                freq_points = 64
            elif token_count == 4 * 63 + 4 + 1:
                freq_points = 63
            else:
                print("âš ï¸ æœªè¯†åˆ«åˆ—æ•°ï¼Œé»˜è®¤ä½¿ç”¨ 4 æ—¶é—´ç‚¹ + 64 é¢‘ç‡ç‚¹")
                freq_points = 64
            num_time_points = 4

        print(f"âœ… æ£€æµ‹ç»“æœï¼š{num_time_points} ä¸ªæ—¶é—´ç‚¹, {freq_points} ä¸ªé¢‘ç‡ç‚¹")

    else:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½• Attention æ–‡ä»¶ï¼Œé»˜è®¤ä½¿ç”¨ 4 ä¸ªæ—¶é—´ç‚¹ + 64 é¢‘ç‡ç‚¹")
        freq_points = 64
        num_time_points = 4

    # æ€» token æ•°ï¼šæ—¶é—´ token + (æ—¶é—´ç‚¹ * é¢‘ç‡ç‚¹ * 2[æ¨¡ + ç›¸])
    numbers = num_time_points + num_time_points * freq_points * 2
    short_numbers = 1 + 1 * freq_points * 2


    for (prefix, pred_num), file_map in pred_dict.items():
        pred_id = f"pred{pred_num}"
        attn_path = os.path.join(folder_path, f"{prefix}_attn_{pred_id}.csv")
        param_attn_path = os.path.join(folder_path, f"{prefix}_param_attn_{pred_id}.csv")
        sal_path = os.path.join(folder_path, f"{prefix}_saliency_{pred_id}.csv")
        ig_path = os.path.join(folder_path, f"{prefix}_ig_{pred_id}.csv")

        missing_files = []
        if not os.path.exists(sal_path):
            missing_files.append(sal_path)
        if not os.path.exists(ig_path):
            missing_files.append(ig_path)

        if missing_files:
            print(f"âŒ ç¼ºå°‘ä»¥ä¸‹æ–‡ä»¶ï¼Œè·³è¿‡ï¼š{', '.join(missing_files)}")
            continue

        # === Attention è¯»å– ===
        has_attn = os.path.exists(attn_path)
        if has_attn:
            attn = pd.read_csv(attn_path, header=None).values.flatten()
            # å‰ num_time_points ä¸ªä¸ºæ—¶é—´ token
            time_tokens = attn[0:num_time_points]
            freq_tokens_raw = attn[num_time_points:]
            freq_tokens_expanded = np.empty(freq_tokens_raw.size * 2)
            freq_tokens_expanded[::2] = freq_tokens_raw
            freq_tokens_expanded[1::2] = freq_tokens_raw
            attn_expanded = np.concatenate([time_tokens, freq_tokens_expanded])[:numbers]

            attn_expanded = np.concatenate([time_tokens, freq_tokens_expanded])[:numbers]
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ° Attention æ–‡ä»¶ï¼Œå°†ä¸ç»˜åˆ¶ Attention æ›²çº¿ï¼š{prefix}_{pred_id}")
            attn_expanded = np.zeros(numbers)

        # === Param_Attn è¯»å– ===
        has_param_attn = os.path.exists(param_attn_path)
        if has_param_attn:
            param_attn = pd.read_csv(param_attn_path, header=None).values.flatten()
            # è·³è¿‡ç¬¬ä¸€åˆ—æ— æ•ˆæ•°æ®
            if len(param_attn) > 1:
                # ==== 1ï¸âƒ£ è§£æç”µå‹token ====
                volt_token = param_attn[1]  # ç”µå‹æ—¶é—´token(å•å€¼)

                # ==== 2ï¸âƒ£ è§£æé˜»æŠ—tokens ====
                freq_tokens_param_raw = param_attn[2:]  # é¢‘ç‡tokens


                # æ‰©å±•é¢‘ç‡tokensï¼ˆå¤åˆ¶ä¸€æ¬¡ç”¨äºå¼ºåº¦å’Œç›¸ä½ï¼‰
                freq_tokens_param_expanded = np.empty(freq_tokens_param_raw.size * 2)
                freq_tokens_param_expanded[::2] = freq_tokens_param_raw
                freq_tokens_param_expanded[1::2] = freq_tokens_param_raw

                # ==== 3ï¸âƒ£ æ„é€ æ‹¼æ¥ç»“æœ ====
                # ç”µå‹éƒ¨åˆ†: [æœ‰æ•ˆå€¼, 0, 0, 0]
                                # ==== 3ï¸âƒ£ æ„é€ æ‹¼æ¥ç»“æœï¼ˆé€‚é…ä»»æ„æ—¶é—´ç‚¹æ•°ï¼‰ ====
                # ç”µå‹éƒ¨åˆ†: é•¿åº¦ = num_time_pointsï¼Œåªæœ‰ç¬¬ 1 ä¸ªæ—¶é—´ç‚¹éé›¶
                volt_block = np.array([volt_token] + [0] * (num_time_points - 1))

                # é˜»æŠ—éƒ¨åˆ†: ç¬¬ 1 ä¸ªæ—¶é—´ç‚¹ä¸ºæœ‰æ•ˆé¢‘ç‡ tokenï¼Œå…¶ä½™æ—¶é—´ç‚¹ä¸º 0
                zero_block = np.zeros_like(freq_tokens_param_expanded)
                blocks = [freq_tokens_param_expanded] + [zero_block] * (num_time_points - 1)
                impe_block = np.concatenate(blocks)

                # æœ€ç»ˆæ‹¼æ¥
                param_all_time = np.concatenate([volt_block, impe_block])


                # æˆªæ–­æˆ–å¡«å……åˆ° numbers é•¿åº¦
                if len(param_all_time) != numbers:
                    raise ValueError(
                        f"âŒ Param_Attn é•¿åº¦ä¸åŒ¹é…: æœŸæœ› {numbers}ï¼Œå®é™… {len(param_all_time)} "
                        f"(prefix={prefix}, pred_id={pred_id})"
                    )
                else:
                    param_attn_expanded = param_all_time

            else:
                print(f"âš ï¸ Param_Attn æ–‡ä»¶æ•°æ®ä¸è¶³ï¼Œå°†ä½¿ç”¨é›¶å¡«å……ï¼š{prefix}_{pred_id}")
                param_attn_expanded = np.zeros(numbers)
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ° Param_Attn æ–‡ä»¶ï¼Œå°†ä¸ç»˜åˆ¶ Param_Attn æ›²çº¿ï¼š{prefix}_{pred_id}")
            param_attn_expanded = np.zeros(numbers)


        sal = pd.read_csv(sal_path)["value"].values
        ig = pd.read_csv(ig_path)["value"].values

        def clean_numeric_array(arr, target_len):
            arr = pd.to_numeric(pd.Series(arr), errors='coerce').dropna().values
            if len(arr) > target_len:
                arr = arr[:target_len]
            elif len(arr) < target_len:
                arr = np.pad(arr, (0, target_len - len(arr)), 'constant')
            return arr

        sal_clean = clean_numeric_array(sal, numbers)
        ig_clean = clean_numeric_array(ig, numbers)

        
                # =============== é¢å¤–ç»˜åˆ¶ï¼šæŒ‰é¢‘ç‡æ±‚å’Œå›¾ ===============
                # =============== é¢å¤–ç»˜åˆ¶ï¼šå››ç±»é¢‘ç‡æ±‚å’Œå¯¹æ¯”å›¾ ===============
        try:
            x_freq = np.arange(freq_points * 2)
            expected_len = numbers  # = num_time_points + num_time_points * freq_points * 2

            # åˆå§‹åŒ–å­˜å‚¨
            volt_sum_attn = volt_sum_param = volt_sum_sal = volt_sum_ig = None
            freq_sum_attn = freq_sum_param = freq_sum_sal = freq_sum_ig = None

            # 1ï¸âƒ£ Attention
            if has_attn:
                if len(attn_expanded) >= num_time_points:
                    volt_sum_attn = np.sum(attn_expanded[:num_time_points])
                if len(attn_expanded) == expected_len:
                    freq_sum_attn = attn_expanded[num_time_points:].reshape(
                        num_time_points, freq_points * 2
                    ).sum(axis=0)

            # 2ï¸âƒ£ Param_Attention
            if has_param_attn:
                if len(param_attn_expanded) >= num_time_points:
                    volt_sum_param = np.sum(param_attn_expanded[:num_time_points])
                if len(param_attn_expanded) == expected_len:
                    freq_sum_param = param_attn_expanded[num_time_points:].reshape(
                        num_time_points, freq_points * 2
                    ).sum(axis=0)

            # 3ï¸âƒ£ Saliency
            if len(sal_clean) >= num_time_points:
                volt_sum_sal = np.sum(sal_clean[:num_time_points])
            if len(sal_clean) == expected_len:
                freq_sum_sal = sal_clean[num_time_points:].reshape(
                    num_time_points, freq_points * 2
                ).sum(axis=0)

            # 4ï¸âƒ£ Integrated Gradients
            if len(ig_clean) >= num_time_points:
                volt_sum_ig = np.sum(ig_clean[:num_time_points])
            if len(ig_clean) == expected_len:
                freq_sum_ig = ig_clean[num_time_points:].reshape(
                    num_time_points, freq_points * 2
                ).sum(axis=0)

            else:
                print(f"âš ï¸ IG æ•°æ®é•¿åº¦ä¸åŒ¹é…: æœŸæœ› {expected_len}ï¼Œå®é™… {len(ig_clean)} ({prefix}_pred{pred_num})")

            # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
            if all(v is None for v in [freq_sum_attn, freq_sum_param, freq_sum_sal, freq_sum_ig]):
                print(f"âš ï¸ æ‰€æœ‰é¢‘ç‡æ±‚å’Œæ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ç»˜å›¾ ({prefix}_pred{pred_num})")
            else:
                # ========== æ„å»ºæ¨ªåæ ‡ï¼š0 è¡¨ç¤ºç”µå‹æ±‚å’Œï¼Œåé¢æ˜¯é¢‘ç‡ç´¢å¼• ==========
                x_all = np.concatenate([[0], x_freq + 1])  # 0=Voltage, å…¶ä½™æ˜¯é¢‘ç‡ç´¢å¼•
                fig_freq, ax1 = plt.subplots(figsize=(18, 5))
                ax2 = ax1.twinx()

                lines_freq = []
                labels_freq = []

                # å·¦è½´æ›²çº¿
                if volt_sum_attn is not None and freq_sum_attn is not None:
                    y_attn = np.concatenate([[volt_sum_attn], freq_sum_attn])
                    l1, = ax1.plot(x_all, y_attn, label="Attention", color='blue')
                    lines_freq.append(l1); labels_freq.append("Attention")

                if volt_sum_param is not None and freq_sum_param is not None:
                    y_param = np.concatenate([[volt_sum_param], freq_sum_param])
                    l2, = ax1.plot(x_all, y_param, label="Param_Attention", color='orange', linestyle='-.')
                    lines_freq.append(l2); labels_freq.append("Param_Attention")

                # å³è½´æ›²çº¿
                if volt_sum_sal is not None and freq_sum_sal is not None:
                    y_sal = np.concatenate([[volt_sum_sal], freq_sum_sal])
                    l3, = ax2.plot(x_all, y_sal, label="Saliency", color='green')
                    lines_freq.append(l3); labels_freq.append("Saliency")

                if volt_sum_ig is not None and freq_sum_ig is not None:
                    y_ig = np.concatenate([[volt_sum_ig], freq_sum_ig])
                    l4, = ax2.plot(x_all, y_ig, label="Integrated Gradients", color='red')
                    lines_freq.append(l4); labels_freq.append("Integrated Gradients")

                # æ ‡ç­¾å’Œç½‘æ ¼
                ax1.set_ylabel("Voltage+Freq Attribution (Attn/Param)", color='blue')
                ax1.tick_params(axis='y', labelcolor='blue')
                ax2.set_ylabel("Voltage+Freq Attribution (Saliency/IG)", color='green')
                ax2.tick_params(axis='y', labelcolor='green')

                ax1.set_title(f"Voltage + Frequency Attribution Summed Over Time ({prefix}_pred{pred_num})")
                ax1.set_xlabel("0=VoltageSum, 1~N=Frequency Token Index")
                ax1.grid(True, linestyle='--', alpha=0.5)
                fig_freq.legend(lines_freq, labels_freq, loc='upper right')
                fig_freq.tight_layout()

                if save_fig:
                    fig_freq.savefig(os.path.join(folder_path, f"{prefix}_pred{pred_num}_volt_freq_sum_plot.png"), dpi=300)
                plt.close(fig_freq)

                # ========== CSV æ•°æ® ==========
                # æ„å»ºé¢‘ç‡æ ‡ç­¾ï¼ˆå«ç”µå‹ï¼‰
                                # ========== CSV æ•°æ® ==========
                # æ„å»ºé¢‘ç‡æ ‡ç­¾ï¼ˆå«ç”µå‹ï¼‰ï¼Œè¿™é‡Œç”¨ç´¢å¼•è€Œä¸æ˜¯å…·ä½“é¢‘ç‡å€¼ï¼Œé¿å…ä¾èµ– freq_values_hz
                freq_labels = ["Voltage_Sum"] + [
                    f"FreqToken_{i+1}" for i in range(freq_points * 2)
                ]


                if len(freq_labels) != len(x_all):
                    print(f"âš ï¸ é¢‘ç‡æ ‡ç­¾é•¿åº¦ä¸åŒ¹é…: æœŸæœ› {len(x_all)}, å®é™… {len(freq_labels)}")
                    freq_labels = [""] * len(x_all)

                csv_data = {
                    "Index": x_all,
                    "Label": freq_labels
                }
                if volt_sum_attn is not None and freq_sum_attn is not None:
                    csv_data["Attention"] = np.concatenate([[volt_sum_attn], freq_sum_attn])
                if volt_sum_param is not None and freq_sum_param is not None:
                    csv_data["Param_Attention"] = np.concatenate([[volt_sum_param], freq_sum_param])
                if volt_sum_sal is not None and freq_sum_sal is not None:
                    csv_data["Saliency"] = np.concatenate([[volt_sum_sal], freq_sum_sal])
                if volt_sum_ig is not None and freq_sum_ig is not None:
                    csv_data["Integrated_Gradients"] = np.concatenate([[volt_sum_ig], freq_sum_ig])

                df_csv = pd.DataFrame(csv_data)
                csv_path = os.path.join(folder_path, f"{prefix}_pred{pred_num}_volt_freq_sum_data.csv")
                df_csv.to_csv(csv_path, index=False, encoding='utf-8-sig')
                print(f"âœ… ç”µå‹+é¢‘ç‡æ±‚å’Œæ•°æ®å·²ä¿å­˜: {csv_path}")

        except Exception as e:
            print(f"âš ï¸ æ— æ³•ç»˜åˆ¶ç”µå‹+é¢‘ç‡æ±‚å’Œå¯¹æ¯”å›¾ ({prefix}_pred{pred_num}): {e}")

        
        
        
        
        
        
        # === ç»˜å›¾ ===
        fig, ax1 = plt.subplots(figsize=(22, 6))
        x = np.arange(numbers)
        lines = []
        labels = []

        print(f"ç»˜å›¾ {prefix}_{pred_id}: x.shape={x.shape}, attn_expanded.shape={attn_expanded.shape}")

        # åˆå§‹åŒ–æ•°æ®å­—å…¸
        csv_data = {
            "Token_Index": x
        }

        # 1ï¸âƒ£ Attention
        if has_attn:
            l1, = ax1.plot(x, attn_expanded, label="Attention", color='blue')
            csv_data["Attention"] = attn_expanded
            lines.append(l1)
            labels.append("Attention")

        # 2ï¸âƒ£ Param_Attention
        if has_param_attn and param_attn_expanded is not None:
            l4, = ax1.plot(np.arange(len(param_attn_expanded)), param_attn_expanded,
                           label="Param_Attention", color='orange', linestyle='-.')
            csv_data["Param_Attention"] = param_attn_expanded
            lines.append(l4)
            labels.append("Param_Attention")

        ax1.set_ylabel("Attention", color='blue')
        ax1.tick_params(axis='y', labelcolor='blue')

        # 3ï¸âƒ£ Saliency
        ax2 = ax1.twinx()
        l2, = ax2.plot(x, sal_clean, label="Saliency", color='green')
        csv_data["Saliency"] = sal_clean
        ax2.set_ylabel("Saliency", color='green')
        ax2.tick_params(axis='y', labelcolor='green')
        lines.append(l2)
        labels.append("Saliency")

        # 4ï¸âƒ£ Integrated Gradients
        ax3 = ax1.twinx()
        ax3.spines["right"].set_position(("axes", 1.05))
        l3, = ax3.plot(x, ig_clean, label="Integrated Gradients", color='red')
        csv_data["Integrated_Gradients"] = ig_clean
        ax3.set_ylabel("IG", color='red')
        ax3.tick_params(axis='y', labelcolor='red')
        lines.append(l3)
        labels.append("Integrated Gradients")

        # åŒºåŸŸåˆ†å‰²æ ‡æ³¨
                # åŒºåŸŸåˆ†å‰²æ ‡æ³¨ï¼ˆé€‚é…ä»»æ„æ—¶é—´ç‚¹æ•°ï¼‰
        segment_labels = ["Time Tokens"] + [f"Freq@T{i+1}" for i in range(num_time_points)]
        block = freq_points * 2  # æ¯ä¸ªæ—¶é—´ç‚¹å¯¹åº”çš„é¢‘ç‡ token æ•°ï¼ˆæ¨¡+ç›¸ï¼‰
        segment_positions = [0, num_time_points]
        for k in range(1, num_time_points + 1):
            segment_positions.append(num_time_points + k * block)

        for i in range(1, len(segment_positions) - 1):
            ax1.axvline(segment_positions[i], color='gray', linestyle='--', alpha=0.4)
            ax1.text(segment_positions[i] + 5, ax1.get_ylim()[1] * 0.9,
                     segment_labels[i], fontsize=12)


        ax1.set_xlim(0, numbers)
        ax1.set_xlabel("Input Token Index (Time + Frequency Domain)")
        ax1.set_title(f"Attribution Visualization ({prefix}_pred{pred_num})")
        ax1.legend(lines, labels, loc='upper right')
        ax1.grid(True, linestyle='--', alpha=0.5)
        fig.tight_layout()

        # === ä¿å­˜å›¾åƒ ===
        if save_fig:
            fig.savefig(os.path.join(folder_path, f"{prefix}_pred{pred_num}_attribution_plot.png"), dpi=300)
        plt.close(fig)
                # === ä¿å­˜ CSV æ•°æ® ===
        csv_data = {
            "Token_Index": x,
            "Token_Type": ["Time"] * num_time_points + ["Freq"] * (numbers - num_time_points)
        }


        # æ·»åŠ é¢‘ç‡æ ‡ç­¾
        if freq_points == 64:
            freq_values_hz = [
                19950, 15850, 12590, 10000, 7943, 6310, 5010, 3980, 3160, 2510, 1990, 1590, 1260, 1000,
                794.3, 631.0, 501.2, 398.1, 316.2, 251.2, 199.5, 158.5, 125.9, 100.0,
                79.43, 63.10, 50.12, 39.81, 31.62, 25.12, 19.95, 15.85, 12.59, 10.0,
                7.94, 6.31, 5.01, 3.98, 3.16, 2.51, 1.99, 1.59, 1.26, 1.0,
                0.7943, 0.6310, 0.5012, 0.3981, 0.3162, 0.2512, 0.1995, 0.1585, 0.1259, 0.1,
                0.07943, 0.06310, 0.05012, 0.03981, 0.03162, 0.02512, 0.01995, 0.01585, 0.01259, 0.01
            ]
        else:
            freq_values_hz = [
                19950, 15850, 12590, 10000, 7943, 6310, 5010, 3980, 3160, 2510, 1990, 1590, 1260, 1000,
                794.3, 631.0, 501.2, 398.1, 316.2, 251.2, 199.5, 158.5, 125.9, 100.0,
                79.43, 63.10, 50.12, 39.81, 31.62, 25.12, 19.95, 15.85, 12.59, 10.0,
                7.94, 6.31, 5.01, 3.98, 3.16, 2.51, 1.99, 1.59, 1.26, 1.0,
                0.7943, 0.6310, 0.5012, 0.3981, 0.3162, 0.2512, 0.1995, 0.1585, 0.1259, 0.1,
                0.07943, 0.06310, 0.05012, 0.03981, 0.03162, 0.02512, 0.01995, 0.01585, 0.01259
            ]

                # æ„å»º Token_Label
        token_labels = ["T1", "T2", "T3", "T4"]
        for t in range(1, 5):  # 4ä¸ªæ—¶é—´ç‚¹
            for f in freq_values_hz:
                token_labels.append(f"{t}_time_{f}_Hz_mag")
                token_labels.append(f"{t}_time_{f}_Hz_phase")

        if len(token_labels) != numbers:
            print(f"âš ï¸ Token_Label é•¿åº¦ä¸åŒ¹é…: æœŸæœ› {numbers}, å®é™… {len(token_labels)}")
            # ç”¨ç©ºå­—ç¬¦ä¸²å¡«å……é¿å…æŠ¥é”™
            token_labels = [""] * numbers

        csv_data["Token_Label"] = token_labels


        # åŠ å…¥å„æ›²çº¿æ•°æ®
        if has_attn:
            csv_data["Attention"] = attn_expanded
        if has_param_attn:
            csv_data["Param_Attention"] = param_attn_expanded
        csv_data["Saliency"] = sal_clean
        csv_data["Integrated_Gradients"] = ig_clean

        df_csv = pd.DataFrame(csv_data)
        csv_path = os.path.join(folder_path, f"{prefix}_pred{pred_num}_attribution_plot_data.csv")
        df_csv.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"âœ… Attribution å›¾æ•°æ®(å«é¢‘ç‡æ ‡ç­¾)å·²ä¿å­˜: {csv_path}")

        
def main():
    parser = argparse.ArgumentParser(description="å¯è§†åŒ–æµ‹è¯•ç»“æœ")
    parser.add_argument("--load_run", type=str, required=True, help="æŒ‡å®šè¦åŠ è½½çš„è¿è¡Œç»“æœæ–‡ä»¶å¤¹åç§°ï¼Œä¾‹å¦‚20250729a")
    args = parser.parse_args()

    base_dir = Path(__file__).resolve().parents[2] / "output" / "inference_results"
    folder_path = base_dir / args.load_run

    if not folder_path.exists():
        raise FileNotFoundError(f"âŒ æŒ‡å®šçš„è¿è¡Œç»“æœç›®å½•ä¸å­˜åœ¨: {folder_path}")

    print(f"ğŸ“‚ æ­£åœ¨å¯è§†åŒ–: {folder_path}")
    plot_attributions_from_folder(str(folder_path), save_fig=True)

if __name__ == "__main__":
    main()
